---
title: 'Project 2: Modeling, Testing, and Predicting'
author: "SDS348"
date: '2020-05-13'
output:
  html_document:
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: yes
  pdf_document:
    toc: yes
---



<div id="introduction" class="section level3">
<h3>Introduction</h3>
<pre class="r"><code>credit &lt;- read.csv(&quot;https://vincentarelbundock.github.io/Rdatasets/csv/ISLR/Credit.csv&quot;)
head(credit)</code></pre>
<pre><code>## X ID Income Limit Rating Cards Age Education Gender
Student Married Ethnicity Balance
## 1 1 1 14.891 3606 283 2 34 11 Male No Yes Caucasian 333
## 2 2 2 106.025 6645 483 3 82 15 Female Yes Yes Asian 903
## 3 3 3 104.593 7075 514 4 71 11 Male No No Asian 580
## 4 4 4 148.924 9504 681 3 36 11 Female No No Asian 964
## 5 5 5 55.882 4897 357 2 68 16 Male No Yes Caucasian 331
## 6 6 6 80.180 8047 569 4 77 10 Male No No Caucasian 1151</code></pre>
<p>The dataset I have chosen is the Credit Card Balance Data, which provides data surrounding credit cards as well as other pertinent customer information. More specifically, the original dataset includes 400 observations of 13 variables: ID (identification), income (in $10,000’s), limit (credit limit), rating (credit rating), cards (number of credit cards), age (in years), education (number of years), gender (male or female), student (yes or no), married (yes or no), ethnicity (African American, Asian, or Caucasian), and Balance (average credit card balance in dollars).</p>
<pre class="r"><code># Assumptions:
  # Multivariate normality
ggplot(credit, aes(x = Limit, y = Balance)) +
geom_point(alpha = .5) + geom_density_2d(h=2) + coord_fixed() + facet_wrap(~Student)</code></pre>
<p><img src="/kproject2_files/figure-html/unnamed-chunk-1-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>  #Homogeneity of covariances 
covmats&lt;-credit%&gt;%group_by(Student)%&gt;%do(covs=cov(.[2:3]))
for(i in 1:2){print(as.character(covmats$Student[i])); print(covmats$covs[i])}</code></pre>
<pre><code>## [1] &quot;No&quot;
## [[1]]
##                ID    Income
## ID     13420.5237  224.8085
## Income   224.8085 1218.6120
## 
## [1] &quot;Yes&quot;
## [[1]]
##                ID    Income
## ID     12991.0763 -485.4826
## Income  -485.4826 1485.8622</code></pre>
<pre class="r"><code># MANOVA
manproj &lt;-manova(cbind(Limit, Balance) ~ Student, data= credit)
summary(manproj)</code></pre>
<pre><code>## Df Pillai approx F num Df den Df Pr(&gt;F)
## Student 1 0.27114 73.841 2 397 &lt; 2.2e-16 ***
## Residuals 398
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<pre class="r"><code>summary.aov(manproj)</code></pre>
<pre><code>## Response Limit :
## Df Sum Sq Mean Sq F value Pr(&gt;F)
## Student 1 76914 76914 0.0144 0.9045
## Residuals 398 2125708072 5340975
##
## Response Balance :
## Df Sum Sq Mean Sq F value Pr(&gt;F)
## Student 1 5658372 5658372 28.622 1.488e-07 ***
## Residuals 398 78681540 197692
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<pre class="r"><code>1-.95^3  # Type 1 Error </code></pre>
<pre><code>## [1] 0.142625</code></pre>
<pre class="r"><code>0.05/3 # Bonferroni  </code></pre>
<pre><code>## [1] 0.01666667</code></pre>
<p>A one-way MANOVA was conducted to determine the effect of Student (Yes or No) on two dependent variables (Balance and Limit). I first checked the assumptions of multivariate normality of DVs and homogeneity of within-group covariance matrices. When testing for multivariate normality of DVs, it was hard to tell if that assumption was met but just from eyeballing it, I could not see any distinct departures. For homogeneity, some values in the covariance matrices were similar while others were not (but overall relative homogeneity).</p>
<p>In total, I ran 3 tests: 1 MANOVA and 2 univariate ANOVAs. I did not run a post-hoc t test since my response variable is binary. To keep the overall type I error rate at 0.05, the boneferroni adjusted signficance level is 0.01666667. After running a MANOVA, I got a p-value of &lt; 0.00000000000000022, Pillai of 0.27114, and a F(2, 397) of 73.841 which means that at least one of my response variables (Balance or Limit) significantly differs by Student status (whether the individual was a student or not). Then I ran 2 univariate ANOVAs and determined that only Balance significantly differs by Student status with a p-value of 0.0000001488 and F(1, 398) value of 28.622. The probability of making at least one type I error (if left unadjusted) is 0.142625.</p>
</div>
<div id="randomization-test" class="section level3">
<h3>Randomization test</h3>
<pre class="r"><code>library(dplyr)
set.seed(348)
head(credit)</code></pre>
<pre><code>## X ID Income Limit Rating Cards Age Education Gender
Student Married Ethnicity Balance
## 1 1 1 14.891 3606 283 2 34 11 Male No Yes Caucasian 333
## 2 2 2 106.025 6645 483 3 82 15 Female Yes Yes Asian 903
## 3 3 3 104.593 7075 514 4 71 11 Male No No Asian 580
## 4 4 4 148.924 9504 681 3 36 11 Female No No Asian 964
## 5 5 5 55.882 4897 357 2 68 16 Male No Yes Caucasian 331
## 6 6 6 80.180 8047 569 4 77 10 Male No No Caucasian 1151</code></pre>
<pre class="r"><code>credit%&gt;%group_by(Married)%&gt;%
  summarize(means=mean(Rating))%&gt;%summarize(`mean_diff:`=diff(means))</code></pre>
<pre><code>## # A tibble: 1 x 1
##   `mean_diff:`
##          &lt;dbl&gt;
## 1         11.7</code></pre>
<pre class="r"><code>rand_distp&lt;-vector()

for(i in 1:5000){
newp&lt;-data.frame(rating=sample(credit$Rating), married=credit$Married) 
rand_distp[i]&lt;-mean(newp[newp$married==&quot;Yes&quot;,]$rating)-
              mean(newp[newp$married==&quot;No&quot;,]$rating)
}

mean(rand_distp&gt;11.65714 | rand_distp&lt; -11.65714)</code></pre>
<pre><code>## [1] 0.4704</code></pre>
<pre class="r"><code># Plot
{hist(rand_distp,main=&quot;&quot;,ylab=&quot;&quot;); abline(v = 11.65714,col=&quot;red&quot;)}</code></pre>
<p><img src="/kproject2_files/figure-html/unnamed-chunk-2-1.png" width="768" style="display: block; margin: auto;" /></p>
<p>I performed a randomization test on my dataset in order to determine if there is a mean difference in credit rating between individuals that are married and those that are unmarried. The null hypothesis is that the mean credit rating is the same for married individuals vs. unmarried individuals. The alternative hypothesis is that the mean credit rating is different for married vs. unmarried individuals. After running my randomization test, I got a p-value of 0.4688. Since this p-value is greater than the alpha value of 0.05, I fail to reject the null hypothesis. In other words, there is no mean difference in credit rating for married vs. unmarried individuals.</p>
</div>
<div id="linear-regression-model" class="section level3">
<h3>Linear Regression Model</h3>
<pre class="r"><code># Linear Regression 
credit$Rating_c&lt;-credit$Rating-mean(credit$Rating, na.rm = &quot;T&quot;)
credit$Income_c&lt;-credit$Income-mean(credit$Income, na.rm = &quot;T&quot;)


p3fit &lt;- lm(Balance ~ Income_c*Rating_c, data= credit)
summary(p3fit)</code></pre>
<pre><code>##
## Call:
## lm(formula = Balance ~ Income_c * Rating_c, data =
credit)
##
## Residuals:
## Min 1Q Median 3Q Max
## -249.53 -111.10 -35.18 54.86 569.66
##
## Coefficients:
## Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 505.403507 9.549534 52.924 &lt; 2e-16 ***
## Income_c -8.398708 0.452875 -18.545 &lt; 2e-16 ***
## Rating_c 3.948726 0.085438 46.217 &lt; 2e-16 ***
## Income_c:Rating_c 0.003394 0.001186 2.863 0.00442 **
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1
##
## Residual standard error: 161.4 on 396 degrees of freedom
## Multiple R-squared: 0.8777, Adjusted R-squared: 0.8767
## F-statistic: 946.9 on 3 and 396 DF, p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code># Plot
p3fit &lt;- lm(Balance ~ Income_c*Rating_c, data= credit)
new1&lt;-credit
new1$Income_c&lt;-mean(credit$Income_c)
new1$mean&lt;-predict(p3fit,new1)
new1$Income_c&lt;-mean(credit$Income_c)+sd(credit$Income_c)
new1$plus.sd&lt;-predict(p3fit,new1)
new1$Income_c&lt;-mean(credit$Income_c)-sd(credit$Income_c)
new1$minus.sd&lt;-predict(p3fit,new1)


mycols&lt;-c(&quot;#619CFF&quot;,&quot;#F8766D&quot;,&quot;#00BA38&quot;)
names(mycols)&lt;-c(&quot;-1 sd&quot;,&quot;mean&quot;,&quot;+1 sd&quot;)
mycols=as.factor(mycols)

ggplot(credit,aes(Rating_c,Balance),group=mycols)+geom_point()+geom_line(data=new1,aes(y=mean,color=&quot;mean&quot;))+geom_line(data=new1,aes(y=plus.sd,color=&quot;+1 sd&quot;))+geom_line(data=new1,aes(y=minus.sd,color=&quot;-1 sd&quot;))+scale_color_manual(values=mycols)+labs(color=&quot;Income (cont)&quot;)+theme(legend.position=c(.9,.2))</code></pre>
<p><img src="/kproject2_files/figure-html/unnamed-chunk-3-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code># Assumptions:
library(sandwich); library(lmtest)
presids&lt;-p3fit$residuals; pfitvals&lt;-p3fit$fitted.values 
ggplot()+geom_point(aes(pfitvals,presids))+geom_hline(yintercept=0, col=&quot;red&quot;) #linearity looks iffy but okay</code></pre>
<p><img src="/kproject2_files/figure-html/unnamed-chunk-3-2.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>bptest(p3fit)  # fail to reject null hypothesis of homoskedasticity</code></pre>
<pre><code>## 
##  studentized Breusch-Pagan test
## 
## data:  p3fit
## BP = 0.77087, df = 3, p-value = 0.8564</code></pre>
<pre class="r"><code>shapiro.test(presids) # reject null hypothesis of normally distributed residuals</code></pre>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  presids
## W = 0.88198, p-value &lt; 2.2e-16</code></pre>
<pre class="r"><code>ggplot()+geom_histogram(aes(presids),bins=20) # can see residuals are skewed to the right!</code></pre>
<p><img src="/kproject2_files/figure-html/unnamed-chunk-3-3.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>coeftest(p3fit, vcov = vcovHC(p3fit)) #robust SE</code></pre>
<pre><code>##
## t test of coefficients:
##
## Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 505.4035074 9.6332553 52.4645 &lt; 2.2e-16 ***
## Income_c -8.3987077 0.4765486 -17.6240 &lt; 2.2e-16 ***
## Rating_c 3.9487257 0.0825803 47.8168 &lt; 2.2e-16 ***
## Income_c:Rating_c 0.0033943 0.0010869 3.1229 0.001922 **
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<pre class="r"><code># Multiple R-squared =  0.8777</code></pre>
<p>After running a linear regression on my data, I got the following interpretations. Intercept: predicted Balance for an average income and rating is 505.403507. Income_c: At an average rating, individuals show a decrease of 8.398708 in balance for every 1-unit increase in income on average. Rating_c: At an average income, individuals show an increase of 3.948726 in balance for every 1-unit increase in rating on average. Income_c:Rating_c: For every one unit increase in rating, the slope for income gets 0.00442 larger.</p>
<p>I checked the assumptions for a linear regression and found that linearity looked okay, homoskedasticity was met (p-value: 0.8564), but my residuals were not normally distributed (p-value: &lt;0.00000000000000022). I made a plot of my residuals and could see that it skewed to the right. I then recomputed the regression results with robust standard errors via ‘coeftest(…,vcov=vcovHC(…))’. Income_c, Rating_c, and Income_c:Rating_c were all significant with p-values of &lt; 0.00000000000000022, &lt; 0.00000000000000022, and 0.001922 respectively. In other words, all these variables are significant predictors of Balance. The p-value for the interaction term changed from 0.00442 to 0.001922 with the robust SEs. Before computing the robust SEs, my SEs were 9.549534, 0.452875, 0.085438, and 0.001186 for the intercept, Income_c, Rating_c, and Income_c:Rating_c respectively. After computing the robust SEs, my SEs were 9.6332553, 0.4765486, 0.0825803, 0.0010869 for the intercept, Income_c, Rating_c, and Income_c:Rating_c respectively. The SEs increased for the intercept and Income_c after computing the robust SEs but decreased for Rating_c and Income_c:Rating_c. The proportion of variation in the outcome my model explains is 0.8777 (multiple r-squared value).</p>
</div>
<div id="linear-regression-model-with-bootstrapped-ses" class="section level3">
<h3>Linear Regression Model with Bootstrapped SEs</h3>
<pre class="r"><code># Bootstrapped SEs (resampling rows)
samp_distn&lt;-replicate(5000, {
boot_dat&lt;-boot_dat&lt;-credit[sample(nrow(credit),replace=TRUE),]
bootp3fit &lt;- lm(Balance ~ Income_c*Rating_c, data= boot_dat)
coef(bootp3fit)
})

# Estimated SEs
samp_distn%&gt;%t%&gt;%as.data.frame%&gt;%summarize_all(sd)</code></pre>
<pre><code>##   (Intercept) Income_c  Rating_c Income_c:Rating_c
## 1    9.385178 0.467314 0.0824125        0.00107979</code></pre>
<pre class="r"><code># Bootstrapped SEs (resampling residuals)
p3fit &lt;- lm(Balance ~ Income_c*Rating_c, data= credit)
presids&lt;-p3fit$residuals
pfitvals&lt;-p3fit$fitted.values
resid_resamp&lt;-replicate(5000,{
new_resids&lt;-sample(presids,replace=TRUE)
newdat&lt;-credit
newdat$new_y&lt;-pfitvals+new_resids
newp3fit&lt;-lm(new_y ~ Income_c*Rating_c, data = newdat)
coef(newp3fit)
})

# Estimated SEs
resid_resamp%&gt;%t%&gt;%as.data.frame%&gt;%summarize_all(sd)</code></pre>
<pre><code>##   (Intercept)  Income_c   Rating_c Income_c:Rating_c
## 1    9.544074 0.4547719 0.08453428       0.001180613</code></pre>
<pre class="r"><code># Comparisons
coeftest(p3fit)[,1:2] # Normal-theory SEs</code></pre>
<pre><code>##                        Estimate  Std. Error
## (Intercept)       505.403507401 9.549534132
## Income_c           -8.398707732 0.452874558
## Rating_c            3.948725693 0.085438390
## Income_c:Rating_c   0.003394308 0.001185629</code></pre>
<pre class="r"><code>coeftest(p3fit, vcov=vcovHC(p3fit))[,1:2] # Robust SEs</code></pre>
<pre><code>##                        Estimate  Std. Error
## (Intercept)       505.403507401 9.633255314
## Income_c           -8.398707732 0.476548559
## Rating_c            3.948725693 0.082580287
## Income_c:Rating_c   0.003394308 0.001086899</code></pre>
<pre class="r"><code>samp_distn%&gt;%t%&gt;%as.data.frame%&gt;%summarize_all(sd) # Bootstrapped SEs (resampling rows)</code></pre>
<pre><code>##   (Intercept) Income_c  Rating_c Income_c:Rating_c
## 1    9.385178 0.467314 0.0824125        0.00107979</code></pre>
<pre class="r"><code>resid_resamp%&gt;%t%&gt;%as.data.frame%&gt;%summarize_all(sd) # Bootstrapped SEs (resampling residuals)</code></pre>
<pre><code>##   (Intercept)  Income_c   Rating_c Income_c:Rating_c
## 1    9.544074 0.4547719 0.08453428       0.001180613</code></pre>
<p>The Bootstrapped SEs from resampling rows for Intercept, Income_c, Rating_c, and Income_c:Rating_c were 9.5378, 0.4787259, 0.08331522, and 0.0010756 respectively. The Bootstrapped SEs from resampling residuals for Intercept, Income_c, Rating_c, and Income_c:Rating_c were 9.546869, 0.4545284, 0.08450937, and 0.001180758 respectively. The original SEs for Intercept, Income_c, Rating_c, and Income_c:Rating_c were 9.549534, 0.452875, 0.085438, and 0.001186 with p-values of &lt; 0.0000000000000002, &lt; 0.0000000000000002, &lt; 0.0000000000000002, and 0.00442 respectively. The robust SEs for Intercept, Income_c, Rating_c, and Income_c:Rating_c were 9.6332553, 0.4765486, 0.0825803, and 0.0010869 with p-values of &lt; 0.00000000000000022, &lt; 0.00000000000000022, &lt; 0.00000000000000022, and 0.001922 respectively.</p>
<p>When looking at SEs: The SEs are all around the same value for each respective variable, give or take a very small increase or decrease in value between the different types of SEs. When looking at p-values: The p-values for Intercept, Income_c, and Rating_c were the same for both robust SEs and the original SEs. However, the p-value for the interaction of Income_c:Rating_c decreased from 0.00442 to 0.001922 for the robust SEs.</p>
</div>
<div id="logistic-regression" class="section level3">
<h3>Logistic Regression</h3>
<pre class="r"><code>library(tidyverse)
library(lmtest)

class_diag &lt;- function(probs,truth){
#CONFUSION MATRIX: CALCULATE ACCURACY, TPR, TNR, PPV
tab&lt;-table(factor(probs&gt;.5,levels=c(&quot;FALSE&quot;,&quot;TRUE&quot;)),truth)
acc=sum(diag(tab))/sum(tab)
sens=tab[2,2]/colSums(tab)[2]
spec=tab[1,1]/colSums(tab)[1]
ppv=tab[2,2]/rowSums(tab)[2]
if(is.numeric(truth)==FALSE &amp; is.logical(truth)==FALSE) truth&lt;-as.numeric(truth)-1
#CALCULATE EXACT AUC
ord&lt;-order(probs, decreasing=TRUE)
probs &lt;- probs[ord]; truth &lt;- truth[ord]
TPR=cumsum(truth)/max(1,sum(truth))
FPR=cumsum(!truth)/max(1,sum(!truth))
dup&lt;-c(probs[-1]&gt;=probs[-length(probs)], FALSE)
TPR&lt;-c(0,TPR[!dup],1); FPR&lt;-c(0,FPR[!dup],1)
n &lt;- length(TPR)
auc&lt;- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )
data.frame(acc,sens,spec,ppv,auc)
} 

# Logistic Regression
logfitp &lt;- glm(Student ~ Balance + Cards, data = credit, family = binomial(link = &quot;logit&quot;))
coeftest(logfitp)</code></pre>
<pre><code>##
## z test of coefficients:
##
## Estimate Std. Error z value Pr(&gt;|z|)
## (Intercept) -3.02690203 0.47586887 -6.3608 2.007e-10 ***
## Balance 0.00182194 0.00037222 4.8948 9.842e-07 ***
## Cards -0.13637228 0.12888924 -1.0581 0.29
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<pre class="r"><code>exp(coef(logfitp))</code></pre>
<pre><code>## (Intercept)     Balance       Cards 
##  0.04846555  1.00182360  0.87251775</code></pre>
<pre class="r"><code>probproj &lt;-predict(logfitp,type=&quot;response&quot;)

# Confusion matrix
table(predict=as.numeric(probproj&gt;.5),truth=credit$Student)%&gt;%addmargins</code></pre>
<pre><code>##        truth
## predict  No Yes Sum
##     0   359  40 399
##     1     1   0   1
##     Sum 360  40 400</code></pre>
<pre class="r"><code>class_diag(probproj, credit$Student) %&gt;% round(4)</code></pre>
<pre><code>##        acc sens   spec ppv   auc
## Yes 0.8975    0 0.9972   0 0.735</code></pre>
<pre class="r"><code># Accuracy 
(359+0)/400</code></pre>
<pre><code>## [1] 0.8975</code></pre>
<pre class="r"><code># Sensitivity (TPR)
0/40</code></pre>
<pre><code>## [1] 0</code></pre>
<pre class="r"><code># Specificity (TNR)
359/360</code></pre>
<pre><code>## [1] 0.9972222</code></pre>
<pre class="r"><code># Recall (PPV)
0/1</code></pre>
<pre><code>## [1] 0</code></pre>
<pre class="r"><code># Density of log-odds plot
credit$logit &lt;-predict(logfitp, type = &quot;link&quot;) #get predicted log-odds
ggplot(credit,aes(logit, fill=Student, color = Student))+geom_density(alpha=.4)+
  geom_vline(xintercept=0,lty=2)</code></pre>
<p><img src="/kproject2_files/figure-html/unnamed-chunk-5-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code># ROC curve
library(plotROC)
ROCcurve&lt;- ggplot(credit)+geom_roc(aes(d=Student, m=probproj), n.cuts=0)
ROCcurve</code></pre>
<p><img src="/kproject2_files/figure-html/unnamed-chunk-5-2.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>calc_auc(ROCcurve)</code></pre>
<pre><code>##   PANEL group       AUC
## 1     1    -1 0.7349653</code></pre>
<pre class="r"><code># 10 fold CV
set.seed(1234)
k=10
pdata&lt;-credit[sample(nrow(credit)),] #randomly order rows
folds&lt;-cut(seq(1:nrow(credit)),breaks=k,labels=F) 

diagp&lt;-NULL
for(i in 1:k){
## Create training and test sets
train&lt;-pdata[folds!=i,]
test&lt;-pdata[folds==i,]
truth&lt;-test$Student
## Train model on training set
trainfit &lt;- glm(Student ~ Balance + Cards, data = train, family = &quot;binomial&quot;)
testprob &lt;-predict(trainfit,newdata = test,type=&quot;response&quot;)
## Test model on test set (save all k results)
diagp&lt;-rbind(diagp,class_diag(testprob,truth))
}
summarize_all(diagp,mean)  </code></pre>
<pre><code>##     acc sens      spec ppv       auc
## 1 0.895    0 0.9946657 NaN 0.7192716</code></pre>
<p>I ran a logistic regression to model the probability of (being a) Student based on the explanatory variables of Balance and Cards. For the intercept: odds of (being a) Student when Balance= 0 and Cards=0, is 0.04846555. For Balance: Controlling for Cards, for every one unit increase in Balance, odds of (being a) Student increase by a factor of 1.00182360 (significant). For Cards: Controlling for Balance, for every one unit increase in Cards, odds of (being a) Student increase by a factor 0.87251775 (not significant). After running a confusion matrix, I got the following: accuracy= 0.8975 (proportion of correctly classified cases), sensitivity= 0 (proprotion of students correctly classified), specificity= 0.9972 (proportion of those that are not students correctly classified), ppv= 0 (proportion classified as a student who actually are). From the ROC curve generated, I calculated the AUC to be 0.7349653. The AUC is the probability that a randomly selected person that is a student has a higher predicted probability than a randomly selected person that is not a student. This AUC value is fair. I then performed a 10-fold CV and got the following out-of-sample Accuracy, Sensitivity, Recall, and AUC respectively: 0.895, 0, NaN, and 0.7192716.</p>
</div>
<div id="lasso" class="section level3">
<h3>LASSO</h3>
<pre class="r"><code>library(dplyr)
ncredit &lt;- credit %&gt;% dplyr::select(-Rating_c, -Income_c, -logit)
# 10-fold CV with linear regression
set.seed(1234)
k=10 #choose number of folds
data1&lt;-ncredit[sample(nrow(ncredit)),] #randomly order rows
folds&lt;-cut(seq(1:nrow(ncredit)),breaks=k,labels=F) #create folds
diags&lt;-NULL
for(i in 1:k){
train&lt;-data1[folds!=i,]
test&lt;-data1[folds==i,]
fit&lt;-lm(Balance~.,data=train)
yhat&lt;-predict(fit,newdata=test)
diags&lt;-mean((test$Balance-yhat)^2)
}
mean(diags)</code></pre>
<pre><code>## [1] 10957.86</code></pre>
<pre class="r"><code># LASSO regression
library(glmnet)
data(ncredit)
y &lt;- as.matrix(ncredit$Balance)
x &lt;- model.matrix(Balance~.,data=ncredit)[,-1]
x &lt;- scale(x)
head(x)</code></pre>
<pre><code>## X ID Income Limit Rating Cards Age Education
## 1 -1.725565 -1.725565 -0.8605053 -0.48938591 -0.46495653
-0.69825535 -1.2561010 -0.7839481
## 2 -1.716916 -1.716916 1.7252765 0.82722509 0.82766657
0.03099306 1.5265388 0.4959672
## 3 -1.708266 -1.708266 1.6846458 1.01351753 1.02802315
0.76024146 0.8888505 -0.7839481
## 4 -1.699617 -1.699617 2.9424671 2.06585321 2.10736343
0.03099306 -1.1401577 -0.7839481
## 5 -1.690967 -1.690967 0.3025489 0.06992465 0.01331402
-0.69825535 0.7149355 0.8159460
## 6 -1.682318 -1.682318 0.9919658 1.43462510 1.38349450
0.76024146 1.2366805 -1.1039270
## GenderFemale StudentYes MarriedYes EthnicityAsian
EthnicityCaucasian
## 1 -1.0343392 -0.3329164 0.794400 -0.5843168 1.0037555
## 2 0.9643839 2.9962477 0.794400 1.7071218 -0.9937679
## 3 -1.0343392 -0.3329164 -1.255665 1.7071218 -0.9937679
## 4 0.9643839 -0.3329164 -1.255665 1.7071218 -0.9937679
## 5 -1.0343392 -0.3329164 0.794400 -0.5843168 1.0037555
## 6 -1.0343392 -0.3329164 -1.255665 -0.5843168 1.0037555</code></pre>
<pre class="r"><code>cv&lt;-cv.glmnet(x,y)
lasso1&lt;-glmnet(x,y,lambda=cv$lambda.1se)
coef(lasso1)</code></pre>
<pre><code>## 14 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                             s0
## (Intercept)         520.015000
## X                     .       
## ID                    .       
## Income             -241.414068
## Limit               393.630135
## Rating              188.360769
## Cards                17.394617
## Age                  -5.880872
## Education             .       
## GenderFemale          .       
## StudentYes          119.585229
## MarriedYes            .       
## EthnicityAsian        .       
## EthnicityCaucasian    .</code></pre>
<pre class="r"><code># LASSO 10-fold CV
ncredit$Yes &lt;- ifelse(ncredit$Student == &quot;Yes&quot;,1,0)
set.seed(1234)
k=10 #choose number of folds
data1&lt;-ncredit[sample(nrow(ncredit)),] #randomly order rows
folds&lt;-cut(seq(1:nrow(ncredit)),breaks=k,labels=F) #create folds
diags&lt;-NULL
for(i in 1:k){
train&lt;-data1[folds!=i,]
test&lt;-data1[folds==i,]
fit&lt;-lm(Balance~Income+Limit+Rating+Cards+Age+Yes,data=train)
yhat&lt;-predict(fit,newdata=test)
diags&lt;-mean((test$Balance-yhat)^2)
}
mean(diags)</code></pre>
<pre><code>## [1] 10944.67</code></pre>
<p>I chose Balance to predict and run a LASSO regression inputting all the rest of my variables as predictors. I first ran a 10-fold CV on my full model and got a MSE of 10957.86. Then I used LASSO for variable selection and found that Income, Limit, Rating, Cards, Age, and Student.Yes are the most important predictors of Balance. I then performed a 10-fold CV using these predictors. After doing so, I got a RMSE of 10944.67. When just comparing the CV MSE for the full model to the LASSO-variables CV MSE, the MSE dropped from 10957.86 with the full model to 10944.67 with the LASSO-variables. While it is not that big of a difference, the LASSO-variables model predicts slightly better.</p>
</div>
